{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inlämningsuppgift: Del 2 - Adversarial input attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Philip Wollsén Ervius \\\n",
    "phao21@student.bth.se\n",
    "\n",
    "Amin Afzali \\\n",
    "moaf@student.bth.se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An implementation of a custom Iterative Fast Gradient Sign Attack (I-FGSA)\n",
    "\n",
    "This notebook contains the implemntation of an adverseial input attack similar to I-FGSA, and a section implementing two defence measures one may use to combat the attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "These are the libraries used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from random import choice\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations\n",
    "\n",
    "We will be using a pretrained Residual Neural Network called ResNet50. Here's how we get it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet-50 model\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define a few functions that will help us execute the attack and display our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for the attack and preparation\n",
    "\n",
    "First we will define a function that classifies an image using the ResNet50 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img) -> int:\n",
    "    \"\"\"Classifies one image and returns the prediction label.\n",
    "\n",
    "    Parameters:\n",
    "        - img: tensor of preprocessed image.\n",
    "\n",
    "    Returns:\n",
    "        - int predicted label for the image.\"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if len(img.shape) == 3:\n",
    "            output = model(img.unsqueeze(0))\n",
    "        else:\n",
    "            output = model(img)\n",
    "\n",
    "    _, pred = torch.max(output, 1)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images\n",
    "\n",
    "We'll use this function to load images into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "    \"\"\"Loads an image from file and returns as a PyTorch tensor.\"\"\"\n",
    "\n",
    "    to_tensor = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    image = Image.open(file_path)\n",
    "    image = to_tensor(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the poisoned image\n",
    "\n",
    "This function calculates the gradient in regards to the loss for the image and the desired label. In our case, it will calculate the loss that prevents the koala from being classified as a tractor. This gives us a value for each pixel (i.e the gradient) which we then subtract, meaning we move our koala image closer to being classified as a tractor. This is done until either the image achieves the desired result, or we surpass the maximum number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attack_image(img, label, step_size = 0.5, max_iter = 100, return_noise_strength= False):\n",
    "    \"\"\"Generates an image that will be classified as label.\n",
    "    \n",
    "    Parameters:\n",
    "        - img: tensor of preprocessed image.\n",
    "        - label: Optional int target label for the image.\n",
    "        - step_size: Optional float noise strength per iteration.\n",
    "                    Lower values may result in a lower noise strength, \n",
    "                    but will take more iterations to complete. Higher values\n",
    "                    can require fewer iterations, but will distort the output more.\n",
    "        - max_iter: Optional int maximum number of steps for generating adverserial image.\n",
    "        - return_noise_strength: Optional bool whether to return a tuple with the image and its \n",
    "                                        noise strength instead of just image. False by default.\n",
    "\n",
    "    Returns:\n",
    "        - tensor of poisoned image with adverserial noise.\n",
    "        - Optional float noise strength. Disabled by default.\n",
    "    \"\"\"\n",
    "\n",
    "    img.requires_grad_(True)\n",
    "    output = img.detach().clone()       # We start by making a copy of the input tensor\n",
    "    if len(img.shape) == 3:\n",
    "        output = output.unsqueeze(0)        # ...add a batch dimension if it doesn't have one\n",
    "    output.requires_grad_(True)         # and then make sure gradient calculations are enabled\n",
    "\n",
    "    criterion = CrossEntropyLoss()\n",
    "    labels = torch.tensor([label])\n",
    "    running_loss = 0.0\n",
    "\n",
    "    print(\"Generating poisoned image\", end=\"\")\n",
    "\n",
    "    i = 0\n",
    "    while (i < max_iter):\n",
    "        print(\".\", end=\"\")\n",
    "\n",
    "        pred = model(output)                    # We start by feeding the image through the model\n",
    "        loss = criterion(pred, labels)          # Then we calculate the loss...\n",
    "\n",
    "        model.zero_grad()                           # ...make sure the gradients are reset\n",
    "        output.grad = None\n",
    "\n",
    "        loss.backward()                             # ...and backpropogae the error to compute the gradient\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        gradient = output.grad                      # If the gradient calculations fail, then we exit\n",
    "        if gradient is None:\n",
    "            break\n",
    "\n",
    "        with torch.no_grad():                           # Otherwise we temporarily pause gradient calculations\n",
    "            output -= gradient * step_size              # so that we can subtract the gradient from our image.\n",
    "\n",
    "            output = torch.clamp(output, 0, 1)                  # Since it may produce invalid pixel values, we clamp values between 1 and 0.\n",
    "\n",
    "        output.requires_grad_(True)                             # After clamping the values, we have to turn the gradient back on.\n",
    "\n",
    "        if classify_image(output) == label:                                             # If the image is classified the way we want...\n",
    "            print(f\" attack image successful with noice strength {i * step_size}\")\n",
    "            if return_noise_strength:\n",
    "                return output.squeeze(0), i * step_size\n",
    "            return output.squeeze(0)                                                        # ...then we remove the batch dimension and return it.\n",
    "\n",
    "        i += 1                                                                  # Otherwise we continue the loop\n",
    "\n",
    "    print(f\" attack image not successful despite noise strength of {i * step_size}\")\n",
    "\n",
    "    if return_noise_strength:\n",
    "        return output.squeeze(0), i * step_size\n",
    "    return output.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting labels and their names\n",
    "\n",
    "These two functions allow us to get the names corresponding to each label, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "urllib.request.urlretrieve(url, \"imagenet_classes.txt\")\n",
    "with open(\"imagenet_classes.txt\") as f:\n",
    "    id_to_label = [line.strip() for line in f.readlines()]\n",
    "\n",
    "def get_class_name(label: int) -> str:\n",
    "    \"\"\"Returns the name of class as string.\"\"\"\n",
    "    return id_to_label[label]\n",
    "\n",
    "def get_label(name: str) -> int:\n",
    "    \"\"\"Returns the label corresponding to the class name.\"\"\"\n",
    "    return id_to_label.index(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing and comparing classifications\n",
    "\n",
    "This function classifies two images and displays them side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_classifications(images: list, extra_info= None):\n",
    "    \"\"\"Classifies and displays a list of images.\n",
    "\n",
    "    Parameters:\n",
    "        - images: list of torch images.\n",
    "        - extra_info: Optional dict[int, str] or list[str] containing extra information\n",
    "                                to be displayed for certain images.\n",
    "    \"\"\"\n",
    "\n",
    "    if not images:\n",
    "        return\n",
    "\n",
    "    max_cols = 5\n",
    "\n",
    "    if len(images) >= max_cols:\n",
    "        cols = max_cols\n",
    "    else:\n",
    "        cols = len(images) % max_cols\n",
    "\n",
    "    rows = len(images) // cols\n",
    "\n",
    "    if rows * cols < len(images):\n",
    "        rows += 1\n",
    "\n",
    "    width = 3.8*cols\n",
    "    height = 3.2*rows\n",
    "\n",
    "    if cols <= 2:\n",
    "        width *= 1.7\n",
    "        height *= 1.7\n",
    "    elif cols == 3:\n",
    "        width *= 1.5\n",
    "        height *= 1.5\n",
    "    fig = plt.figure(figsize= (width, height))\n",
    "    axes = fig.subplots(nrows= rows, ncols= cols)\n",
    "\n",
    "    if rows == 1 and cols == 1:                 # Make sure axes is always 2D for indicing\n",
    "        axes = np.array([[axes]])\n",
    "    elif rows == 1 or cols == 1:\n",
    "        axes = np.array(axes).reshape(rows, cols)\n",
    "    else:\n",
    "        axes = np.array(axes)\n",
    "\n",
    "    to_pil_image = transforms.Compose([transforms.ToPILImage()])\n",
    "\n",
    "    for i in range(rows * cols):\n",
    "\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "\n",
    "        if i >= len(images):\n",
    "            fig.delaxes(axes[row][col])\n",
    "            continue\n",
    "\n",
    "        img = images[i]\n",
    "\n",
    "        if len(img.shape) == 4:\n",
    "            disp_img = to_pil_image(img.squeeze(0).permute(1, 2, 0))\n",
    "        else:\n",
    "            disp_img = to_pil_image(img)\n",
    "\n",
    "        axes[row][col].imshow(disp_img)\n",
    "\n",
    "        image = img.detach().unsqueeze(0)\n",
    "\n",
    "        pred = classify_image(image)\n",
    "\n",
    "        title = f\"Predicted: {get_class_name(pred.item())}\"\n",
    "\n",
    "        if extra_info:\n",
    "            try:\n",
    "                title += f\"{extra_info[i]}\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        axes[row][col].set_title(title)\n",
    "        axes[row][col].axis('off')\n",
    "\n",
    "    fig.patch.set_facecolor(\"lightgray\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the attack\n",
    "\n",
    "First we retrieve the image and the desired label for our attack, in this case the koala image and the label for tractor. Then we use these to create a poisoned image of the koala that will be classified as a tractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attackutförande\n",
    "\n",
    "tractor_label = get_label(\"tractor\")\n",
    "koala_image = load_image(\"images\\\\koala.jpeg\")\n",
    "\n",
    "step_size = 0.11\n",
    "\n",
    "poisoned_image = create_attack_image(koala_image, tractor_label, step_size= step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of the attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the original and the poisoned image is classified and displayed. There are very small visual differences between the two, yet they're classified very differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_classifications([koala_image, poisoned_image])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defence measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for the defence part\n",
    "\n",
    "A part of the defence will involve training the model on new images. Here's the function we'll use for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(img, label):\n",
    "    \"\"\"Trains the model on an image.\n",
    "\n",
    "    Parameters:\n",
    "        - img: tensor of preprocessed image.\n",
    "        - label: int target label for the image.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(img.shape) == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Prepare the input and label\n",
    "    labels = torch.tensor([label])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(img)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    # print(f'Loss: {running_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also analyse the distributions of images to further our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(image):\n",
    "    \"\"\"Calculates and returns array of mean and std for each channel in image.\"\"\"\n",
    "    std, mean = torch.std_mean(image, axis=(1, 2))\n",
    "    return tuple(mean.detach().numpy()) + tuple(std.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations\n",
    "\n",
    "First we will take a closer look at the adversarial noise. To do this, we will generate a number of images with differing noise strenghts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_poisoned_data(n= 12, step_size_range = (0.1, 24), return_noise_strength= True, random_label= True):\n",
    "    \"\"\"Generates n poisoned images. Returns a tuple with a list of images and a list of noise strengths.\n",
    "\n",
    "    Parameters:\n",
    "        - n: Optional int number of images to generate. Default is 12.\n",
    "        - step_size_range: Optional tuple with min/max values for step_size.\n",
    "        - return_noise_strength: Optional bool whether to also return a list of the \n",
    "                                noise strengths for each image. True by default.        \n",
    "        - random_label: Optional bool whether to use a random target label. If False, the label'tractor' \n",
    "                                will be used. True by default.\n",
    "    \"\"\"\n",
    "\n",
    "    poisoned_data = []\n",
    "\n",
    "    low = step_size_range[0]\n",
    "    high = step_size_range[1]\n",
    "\n",
    "    step_size_delta = (high - low) / n\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        step_size = low + step_size_delta * i\n",
    "\n",
    "        if random_label:\n",
    "            label = get_label(choice(id_to_label))\n",
    "        else:\n",
    "            label = tractor_label\n",
    "\n",
    "        img, noise_strength = create_attack_image(koala_image, label, step_size, return_noise_strength= True)\n",
    "        poisoned_data.append((img, noise_strength))\n",
    "\n",
    "    poisoned_data.sort(key= lambda pair: pair[1])        # Sort by noise strength\n",
    "\n",
    "    poisoned_images = [pair[0] for pair in poisoned_data]\n",
    "    noise_strengths = [round(pair[1], 2) for pair in poisoned_data]\n",
    "\n",
    "    if return_noise_strength:\n",
    "        return poisoned_images, noise_strengths\n",
    "    return poisoned_images\n",
    "\n",
    "# Generate images with a wide range of noise strengths\n",
    "\n",
    "poisoned_images, noise_strengths = generate_poisoned_data(10, (0.1, 12.3), random_label= False)\n",
    "new_poisoned_images, new_noise_strengths = generate_poisoned_data(6, (13, 34), random_label= False)\n",
    "poisoned_images.extend(new_poisoned_images)\n",
    "noise_strengths.extend(new_noise_strengths)\n",
    "\n",
    "noise_info = [f\", Noise strength: {round(value, 2)}\" for value in noise_strengths]\n",
    "display_classifications(poisoned_images, extra_info= noise_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise remains subtle until we reach a noise strength of around 5. By the time the noise reaches 10, it's abundantly clear that the image has been altered, while higher values completely distort the image.\n",
    "\n",
    "### Let's analyse the distribution of RGB values for poisoned images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distributions = [get_distribution(img) for img in poisoned_images]\n",
    "\n",
    "# Plot settings\n",
    "channels = [\"Red\", \"Green\", \"Blue\"]\n",
    "colors = [\"Reds\", \"Greens\", \"Blues\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), constrained_layout=True)\n",
    "\n",
    "for i, (channel, color) in enumerate(zip(channels, colors)):\n",
    "    means = [dist[i] for dist in distributions]      # Extract means for the current channel\n",
    "    stds = [dist[i + 3] for dist in distributions]  # Extract stds for the current channel\n",
    "    ax = axes[i]\n",
    "    scatter = ax.scatter(means, stds, c=noise_strengths, cmap=color, s=100, edgecolor='black')\n",
    "    ax.set_title(f\"{channel} Channel\")\n",
    "    ax.set_xlabel(\"Mean\")\n",
    "    ax.set_ylabel(\"Standard Deviation\")\n",
    "    ax.grid(False)\n",
    "    fig.colorbar(scatter, ax=ax, label=\"Noise Strength\")\n",
    "\n",
    "fig.patch.set_facecolor(\"lightgray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are clear differences between the distributions of poisoned images given their noise strengths.\n",
    "\n",
    "### Now we fit a Random Forest to detect the images with excessive noise.\n",
    "\n",
    "We'll begin by putting together the dataset with the distributions, and adding a threshold that will determine whether the image has excessive noise or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold = 6\n",
    "distributions = [get_distribution(img) for img in poisoned_images]\n",
    "\n",
    "labels = {0: \"Low amount of noise\", 1: \"Excessive amount of noise\"}\n",
    "noise_detection_labels = [0 for _ in distributions]                         # Mark each data point as zero\n",
    "\n",
    "for i, noise_strength in enumerate(noise_strengths):\n",
    "\n",
    "    if noise_strength > threshold:\n",
    "        noise_detection_labels[i] = 1                           # If the noise is above the threshold then change the label to 1\n",
    "\n",
    "class_counts = [noise_detection_labels.count(0), noise_detection_labels.count(1)]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.bar([0, 1], class_counts, color=[\"forestgreen\", \"firebrick\"], width=0.8, zorder=2)\n",
    "ax.grid(axis=\"y\", alpha=0.7, zorder= 1)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"Low amount of noise\", \"Excessive noise\"])\n",
    "ax.set_ylabel(\"Number of Samples\")\n",
    "ax.set_title(\"Distribution of samples\")\n",
    "fig.patch.set_facecolor(\"lightgray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The defence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train our model on the poisoned images, and then we fit the Random Forest to detect when there's heavy noise in the images.\n",
    "It's important to limit the amount of noise we allow in the images we use for retraining the model; it still needs to resemble a koala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_noise_strength_for_training = 60\n",
    "\n",
    "for image, noise_strength in zip(poisoned_images, noise_strengths):\n",
    "    if noise_strength > max_noise_strength_for_training:\n",
    "        continue\n",
    "    train(image, get_label(\"koala\"))\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(distributions, noise_detection_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of the defence measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generation of adverserial images usually takes between 2-5 iterations. Now we will see that it will take much longer, and even then it may not achieve the desired classification. At this point, the random forest will try to determine whether it contains exessive noise or not. We will put a limit of 50 iterations for generating the poisoned image, but you can increase it if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to change these parameters if you want to try more iterations or a higher step_size\n",
    "max_iter = 50\n",
    "step_size = 5           # Higher step size in order to speed up generation\n",
    "\n",
    "poisoned_image = create_attack_image(koala_image, tractor_label, step_size= step_size, max_iter = max_iter)\n",
    "\n",
    "poisoned_prediction = rf.predict([get_distribution(poisoned_image)])\n",
    "koala_prediction = rf.predict([get_distribution(koala_image)])\n",
    "\n",
    "display_classifications([poisoned_image, koala_image], extra_info= [\", \" + labels[poisoned_prediction[0]], \", \" + labels[koala_prediction[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make this defence truly robust, one must generate adversarial images for all classes and train the model on those too. Otherwise model might learn to associate the noise with a certain class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referenser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is inspired by the math taught in the multivariable calculus course and the various AI-courses on BTH."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
